{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Weight Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch import tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "\n",
    "from base_code.models.poc import NeuralNetwork as NN\n",
    "from base_code.datasets import DryBeansDataset as DBD\n",
    "from base_code.train_test import train, test\n",
    "\n",
    "from base_code.preprocessing.nomalize_standarizer import pipeline as normalize_standarize\n",
    "from base_code.dataloaders.base import ContinualLearningDataLoader as DataLoader\n",
    "from base_code.losses.ewc import EWC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DBD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_task_range(0, 2).labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = normalize_standarize(dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.transform(dataset.features)\n",
    "dataset.features = X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(features_shape=dataset.features_shape, output_shape=dataset.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = EWC(importance=1)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.938606  [   10/13611]\n",
      "loss: 1.926388  [ 1010/13611]\n",
      "loss: 1.933463  [ 2010/13611]\n",
      "loss: 1.926143  [ 3010/13611]\n",
      "loss: 1.926182  [ 4010/13611]\n",
      "loss: 1.917880  [ 5010/13611]\n",
      "loss: 1.893715  [ 6010/13611]\n",
      "loss: 1.652866  [ 7010/13611]\n",
      "loss: 1.750546  [ 8010/13611]\n",
      "loss: 1.654315  [ 9010/13611]\n",
      "loss: 1.549801  [10010/13611]\n",
      "loss: 1.812034  [11010/13611]\n",
      "loss: 1.818748  [12010/13611]\n",
      "loss: 1.748461  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 38.1%, Avg loss: 1.761336 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.897772  [   10/13611]\n",
      "loss: 1.733104  [ 1010/13611]\n",
      "loss: 1.798549  [ 2010/13611]\n",
      "loss: 1.718744  [ 3010/13611]\n",
      "loss: 1.582367  [ 4010/13611]\n",
      "loss: 1.888248  [ 5010/13611]\n",
      "loss: 1.880362  [ 6010/13611]\n",
      "loss: 1.779645  [ 7010/13611]\n",
      "loss: 1.794405  [ 8010/13611]\n",
      "loss: 1.629606  [ 9010/13611]\n",
      "loss: 1.616499  [10010/13611]\n",
      "loss: 1.873621  [11010/13611]\n",
      "loss: 1.739490  [12010/13611]\n",
      "loss: 1.895439  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 1.720913 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.727703  [   10/13611]\n",
      "loss: 1.630079  [ 1010/13611]\n",
      "loss: 1.903957  [ 2010/13611]\n",
      "loss: 1.852506  [ 3010/13611]\n",
      "loss: 1.845416  [ 4010/13611]\n",
      "loss: 1.496475  [ 5010/13611]\n",
      "loss: 1.649513  [ 6010/13611]\n",
      "loss: 1.658396  [ 7010/13611]\n",
      "loss: 1.637642  [ 8010/13611]\n",
      "loss: 1.771584  [ 9010/13611]\n",
      "loss: 1.591582  [10010/13611]\n",
      "loss: 1.903499  [11010/13611]\n",
      "loss: 1.566886  [12010/13611]\n",
      "loss: 1.818201  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.699493 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.869896  [   10/13611]\n",
      "loss: 1.605513  [ 1010/13611]\n",
      "loss: 1.728784  [ 2010/13611]\n",
      "loss: 1.692254  [ 3010/13611]\n",
      "loss: 1.596139  [ 4010/13611]\n",
      "loss: 1.792990  [ 5010/13611]\n",
      "loss: 1.611082  [ 6010/13611]\n",
      "loss: 1.567823  [ 7010/13611]\n",
      "loss: 1.837901  [ 8010/13611]\n",
      "loss: 1.798895  [ 9010/13611]\n",
      "loss: 1.663272  [10010/13611]\n",
      "loss: 1.761324  [11010/13611]\n",
      "loss: 1.681240  [12010/13611]\n",
      "loss: 1.519743  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.659731 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.824099  [   10/13611]\n",
      "loss: 1.819590  [ 1010/13611]\n",
      "loss: 1.659597  [ 2010/13611]\n",
      "loss: 1.860346  [ 3010/13611]\n",
      "loss: 1.603911  [ 4010/13611]\n",
      "loss: 1.678077  [ 5010/13611]\n",
      "loss: 1.655076  [ 6010/13611]\n",
      "loss: 1.514668  [ 7010/13611]\n",
      "loss: 1.429890  [ 8010/13611]\n",
      "loss: 1.611667  [ 9010/13611]\n",
      "loss: 1.552439  [10010/13611]\n",
      "loss: 1.720653  [11010/13611]\n",
      "loss: 1.571555  [12010/13611]\n",
      "loss: 1.420187  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.535333 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model, train_dataloader, loss_fn, optimizer)\n",
    "    test(model, train_dataloader, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.276212  [   10/ 2027]\n",
      "loss: 1.297114  [ 1010/ 2027]\n",
      "loss: 1.187896  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 1.201651 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.204704  [   10/ 2027]\n",
      "loss: 1.175839  [ 1010/ 2027]\n",
      "loss: 1.219845  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 1.185685 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.166602  [   10/ 2027]\n",
      "loss: 1.170341  [ 1010/ 2027]\n",
      "loss: 1.174511  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 1.178281 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.179792  [   10/ 2027]\n",
      "loss: 1.168353  [ 1010/ 2027]\n",
      "loss: 1.172774  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 1.174184 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165649  [   10/ 2027]\n",
      "loss: 1.165880  [ 1010/ 2027]\n",
      "loss: 1.173934  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.171874 \n",
      "\n",
      "Task 2\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.112403  [   10/ 1322]\n",
      "loss: 2.112149  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.541163 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.102550  [   10/ 1322]\n",
      "loss: 2.092286  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.534869 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.099954  [   10/ 1322]\n",
      "loss: 1.842562  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 1.220457 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.355424  [   10/ 1322]\n",
      "loss: 1.176173  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 1.191743 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.181103  [   10/ 1322]\n",
      "loss: 1.169820  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 1.190983 \n",
      "\n",
      "Task 3\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322020 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322345 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165421  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322018 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322035 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.165421  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322020 \n",
      "\n",
      "Task 4\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.164654  [   10/ 1630]\n",
      "loss: 2.163928  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.570972 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.161106  [   10/ 1630]\n",
      "loss: 2.162145  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.570907 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.163572  [   10/ 1630]\n",
      "loss: 2.164357  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.570819 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.160835  [   10/ 1630]\n",
      "loss: 2.154101  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.570222 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.154273  [   10/ 1630]\n",
      "loss: 1.187674  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.508206 \n",
      "\n",
      "Task 5\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.955737  [   10/ 1928]\n",
      "loss: 1.236516  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.606281 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.190040  [   10/ 1928]\n",
      "loss: 1.273422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.623141 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.168507  [   10/ 1928]\n",
      "loss: 1.168737  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 1.626410 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.172681  [   10/ 1928]\n",
      "loss: 1.166759  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.627724 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.236825  [   10/ 1928]\n",
      "loss: 1.170189  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.628125 \n",
      "\n",
      "Task 6\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.105368  [   10/ 2636]\n",
      "loss: 2.050176  [ 1010/ 2636]\n",
      "loss: 1.814025  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.581925 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.490117  [   10/ 2636]\n",
      "loss: 1.282908  [ 1010/ 2636]\n",
      "loss: 1.201879  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.8%, Avg loss: 1.853275 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.192948  [   10/ 2636]\n",
      "loss: 1.187344  [ 1010/ 2636]\n",
      "loss: 1.183368  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.887329 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.186135  [   10/ 2636]\n",
      "loss: 1.172725  [ 1010/ 2636]\n",
      "loss: 1.172441  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.895598 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.172663  [   10/ 2636]\n",
      "loss: 1.173614  [ 1010/ 2636]\n",
      "loss: 1.168674  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.898831 \n",
      "\n",
      "Task 7\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165407  [   10/ 3546]\n",
      "loss: 2.165038  [ 1010/ 3546]\n",
      "loss: 2.165250  [ 2010/ 3546]\n",
      "loss: 2.165350  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.968324 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165366  [   10/ 3546]\n",
      "loss: 2.165125  [ 1010/ 3546]\n",
      "loss: 2.165105  [ 2010/ 3546]\n",
      "loss: 2.165322  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.968241 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165301  [   10/ 3546]\n",
      "loss: 2.164597  [ 1010/ 3546]\n",
      "loss: 2.165359  [ 2010/ 3546]\n",
      "loss: 2.165192  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.968152 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.165389  [   10/ 3546]\n",
      "loss: 2.165353  [ 1010/ 3546]\n",
      "loss: 2.165312  [ 2010/ 3546]\n",
      "loss: 2.165298  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.967399 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.165152  [   10/ 3546]\n",
      "loss: 2.165005  [ 1010/ 3546]\n",
      "loss: 2.165020  [ 2010/ 3546]\n",
      "loss: 2.165182  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.967948 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for task_id in range(train_dataloader.get_tasks_length()):\n",
    "    print(f\"Task {task_id+1}\\n-------------------------------\")\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(model, train_dataloader.get_task(task_id), loss_fn, optimizer)\n",
    "        test(model, train_dataloader.get_task_range(0, task_id+1), loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

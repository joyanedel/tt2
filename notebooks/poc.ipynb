{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "\n",
    "from base_code.models.poc import NeuralNetwork as NN\n",
    "from base_code.datasets import DryBeansDataset as DBD\n",
    "from base_code.train_test import train, test\n",
    "\n",
    "from base_code.preprocessing.nomalize_standarizer import pipeline as normalize_standarize\n",
    "from base_code.dataloaders.base import ContinualLearningDataLoader as DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DBD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_task_range(0, 2).labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = normalize_standarize(dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.transform(dataset.features)\n",
    "dataset.features = X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(features_shape=dataset.features_shape, output_shape=dataset.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.633937  [   10/13611]\n",
      "loss: 1.266453  [ 1010/13611]\n",
      "loss: 1.165857  [ 2010/13611]\n",
      "loss: 1.165542  [ 3010/13611]\n",
      "loss: 1.465427  [ 4010/13611]\n",
      "loss: 1.265411  [ 5010/13611]\n",
      "loss: 1.265865  [ 6010/13611]\n",
      "loss: 1.358413  [ 7010/13611]\n",
      "loss: 1.265203  [ 8010/13611]\n",
      "loss: 1.365419  [ 9010/13611]\n",
      "loss: 1.265438  [10010/13611]\n",
      "loss: 1.445026  [11010/13611]\n",
      "loss: 1.234348  [12010/13611]\n",
      "loss: 1.465557  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 1.390860 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model, train_dataloader, loss_fn, optimizer)\n",
    "    test(model, train_dataloader, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.135342  [   10/ 2027]\n",
      "loss: 1.165468  [ 1010/ 2027]\n",
      "loss: 1.165423  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.166078 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.165427  [   10/ 2027]\n",
      "loss: 1.165600  [ 1010/ 2027]\n",
      "loss: 1.165424  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.165626 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.165423  [   10/ 2027]\n",
      "loss: 1.165423  [ 1010/ 2027]\n",
      "loss: 1.165424  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.165498 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.165424  [   10/ 2027]\n",
      "loss: 1.165425  [ 1010/ 2027]\n",
      "loss: 1.165426  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.165466 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165427  [   10/ 2027]\n",
      "loss: 1.165423  [ 1010/ 2027]\n",
      "loss: 1.165422  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.165453 \n",
      "\n",
      "Task 2\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1322]\n",
      "loss: 2.165421  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.560194 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1322]\n",
      "loss: 2.165408  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.560159 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165421  [   10/ 1322]\n",
      "loss: 2.159308  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.549323 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.136811  [   10/ 1322]\n",
      "loss: 1.935270  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 1.219446 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 1322]\n",
      "loss: 1.165422  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 1.227748 \n",
      "\n",
      "Task 3\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.355009 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.355013 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.357333 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.355014 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.355013 \n",
      "\n",
      "Task 4\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1630]\n",
      "loss: 2.165421  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.595343 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1630]\n",
      "loss: 2.165422  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.596350 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1630]\n",
      "loss: 2.165422  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.597230 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1630]\n",
      "loss: 2.165422  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.598611 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/ 1630]\n",
      "loss: 2.165422  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.599569 \n",
      "\n",
      "Task 5\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.454466  [   10/ 1928]\n",
      "loss: 1.165422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 1.595619 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 1928]\n",
      "loss: 1.165422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.627612 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 1928]\n",
      "loss: 1.165422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.689677 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 1928]\n",
      "loss: 1.165422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 1.722015 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 1928]\n",
      "loss: 1.165422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 1.740967 \n",
      "\n",
      "Task 6\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.104009  [   10/ 2636]\n",
      "loss: 1.165456  [ 1010/ 2636]\n",
      "loss: 1.165423  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.710453 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.165423  [   10/ 2636]\n",
      "loss: 1.165427  [ 1010/ 2636]\n",
      "loss: 1.165453  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 1.728839 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.165570  [   10/ 2636]\n",
      "loss: 1.165425  [ 1010/ 2636]\n",
      "loss: 1.165423  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 1.737188 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.165423  [   10/ 2636]\n",
      "loss: 1.165423  [ 1010/ 2636]\n",
      "loss: 1.165423  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 1.746831 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165423  [   10/ 2636]\n",
      "loss: 1.165425  [ 1010/ 2636]\n",
      "loss: 1.165423  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 1.753924 \n",
      "\n",
      "Task 7\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165421  [   10/ 3546]\n",
      "loss: 2.165420  [ 1010/ 3546]\n",
      "loss: 2.165403  [ 2010/ 3546]\n",
      "loss: 1.165511  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.666380 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.165727  [   10/ 3546]\n",
      "loss: 1.165436  [ 1010/ 3546]\n",
      "loss: 1.165991  [ 2010/ 3546]\n",
      "loss: 1.165427  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 1.733698 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 3546]\n",
      "loss: 1.165787  [ 1010/ 3546]\n",
      "loss: 1.165454  [ 2010/ 3546]\n",
      "loss: 1.165890  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.742064 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.165423  [   10/ 3546]\n",
      "loss: 1.165424  [ 1010/ 3546]\n",
      "loss: 1.165459  [ 2010/ 3546]\n",
      "loss: 1.165469  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.747544 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165422  [   10/ 3546]\n",
      "loss: 1.165422  [ 1010/ 3546]\n",
      "loss: 1.165435  [ 2010/ 3546]\n",
      "loss: 1.165444  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 1.751998 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for task_id in range(train_dataloader.get_tasks_length()):\n",
    "    print(f\"Task {task_id+1}\\n-------------------------------\")\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(model, train_dataloader.get_task(task_id), loss_fn, optimizer)\n",
    "        test(model, train_dataloader.get_task_range(0, task_id+1), loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "\n",
    "from base_code.models.poc import NeuralNetwork as NN\n",
    "from base_code.datasets import DryBeansDataset as DBD\n",
    "from base_code.train_test import train, test\n",
    "\n",
    "from base_code.preprocessing.nomalize_standarizer import pipeline as normalize_standarize\n",
    "from base_code.dataloaders.base import ContinualLearningDataLoader as DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DBD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_task_range(0, 2).labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = normalize_standarize(dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.transform(dataset.features)\n",
    "dataset.features = X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(features_shape=dataset.features_shape, output_shape=dataset.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.956650  [   10/13611]\n",
      "loss: 1.960915  [ 1010/13611]\n",
      "loss: 1.942756  [ 2010/13611]\n",
      "loss: 1.937229  [ 3010/13611]\n",
      "loss: 1.939797  [ 4010/13611]\n",
      "loss: 1.935474  [ 5010/13611]\n",
      "loss: 1.904520  [ 6010/13611]\n",
      "loss: 1.936473  [ 7010/13611]\n",
      "loss: 1.887173  [ 8010/13611]\n",
      "loss: 1.890128  [ 9010/13611]\n",
      "loss: 1.871152  [10010/13611]\n",
      "loss: 1.741034  [11010/13611]\n",
      "loss: 1.920559  [12010/13611]\n",
      "loss: 1.717723  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 1.783969 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.869239  [   10/13611]\n",
      "loss: 1.672736  [ 1010/13611]\n",
      "loss: 1.741121  [ 2010/13611]\n",
      "loss: 1.715134  [ 3010/13611]\n",
      "loss: 1.930799  [ 4010/13611]\n",
      "loss: 1.858136  [ 5010/13611]\n",
      "loss: 1.805385  [ 6010/13611]\n",
      "loss: 1.682133  [ 7010/13611]\n",
      "loss: 1.813624  [ 8010/13611]\n",
      "loss: 1.528674  [ 9010/13611]\n",
      "loss: 1.757904  [10010/13611]\n",
      "loss: 1.672263  [11010/13611]\n",
      "loss: 1.558595  [12010/13611]\n",
      "loss: 1.707351  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.711778 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.664005  [   10/13611]\n",
      "loss: 1.613067  [ 1010/13611]\n",
      "loss: 1.655629  [ 2010/13611]\n",
      "loss: 1.526098  [ 3010/13611]\n",
      "loss: 1.752091  [ 4010/13611]\n",
      "loss: 1.665289  [ 5010/13611]\n",
      "loss: 1.726543  [ 6010/13611]\n",
      "loss: 1.669176  [ 7010/13611]\n",
      "loss: 1.475382  [ 8010/13611]\n",
      "loss: 1.733172  [ 9010/13611]\n",
      "loss: 1.729506  [10010/13611]\n",
      "loss: 1.643946  [11010/13611]\n",
      "loss: 1.691518  [12010/13611]\n",
      "loss: 1.605909  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.615452 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.450639  [   10/13611]\n",
      "loss: 1.593324  [ 1010/13611]\n",
      "loss: 1.396034  [ 2010/13611]\n",
      "loss: 1.524679  [ 3010/13611]\n",
      "loss: 1.466488  [ 4010/13611]\n",
      "loss: 1.401218  [ 5010/13611]\n",
      "loss: 1.782586  [ 6010/13611]\n",
      "loss: 1.639348  [ 7010/13611]\n",
      "loss: 1.819223  [ 8010/13611]\n",
      "loss: 1.556461  [ 9010/13611]\n",
      "loss: 1.642053  [10010/13611]\n",
      "loss: 1.748359  [11010/13611]\n",
      "loss: 1.713891  [12010/13611]\n",
      "loss: 1.563210  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.566265 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.639951  [   10/13611]\n",
      "loss: 1.587856  [ 1010/13611]\n",
      "loss: 1.423029  [ 2010/13611]\n",
      "loss: 1.454252  [ 3010/13611]\n",
      "loss: 1.653824  [ 4010/13611]\n",
      "loss: 1.557951  [ 5010/13611]\n",
      "loss: 1.743642  [ 6010/13611]\n",
      "loss: 1.640905  [ 7010/13611]\n",
      "loss: 1.697791  [ 8010/13611]\n",
      "loss: 1.690607  [ 9010/13611]\n",
      "loss: 1.377963  [10010/13611]\n",
      "loss: 1.529921  [11010/13611]\n",
      "loss: 1.503395  [12010/13611]\n",
      "loss: 1.808564  [13010/13611]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 1.510092 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model, train_dataloader, loss_fn, optimizer)\n",
    "    test(model, train_dataloader, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.276212  [   10/ 2027]\n",
      "loss: 1.297114  [ 1010/ 2027]\n",
      "loss: 1.187896  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 1.201651 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.204704  [   10/ 2027]\n",
      "loss: 1.175839  [ 1010/ 2027]\n",
      "loss: 1.219845  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 1.185685 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.166602  [   10/ 2027]\n",
      "loss: 1.170341  [ 1010/ 2027]\n",
      "loss: 1.174511  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 1.178281 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.179792  [   10/ 2027]\n",
      "loss: 1.168353  [ 1010/ 2027]\n",
      "loss: 1.172774  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 1.174184 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.165649  [   10/ 2027]\n",
      "loss: 1.165880  [ 1010/ 2027]\n",
      "loss: 1.173934  [ 2010/ 2027]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 1.171874 \n",
      "\n",
      "Task 2\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.112403  [   10/ 1322]\n",
      "loss: 2.112149  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.541163 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.102550  [   10/ 1322]\n",
      "loss: 2.092286  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.534869 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.099954  [   10/ 1322]\n",
      "loss: 1.842562  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 1.220457 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.355424  [   10/ 1322]\n",
      "loss: 1.176173  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 1.191743 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.181103  [   10/ 1322]\n",
      "loss: 1.169820  [ 1010/ 1322]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 1.190983 \n",
      "\n",
      "Task 3\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322020 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322345 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165421  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322018 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.165422  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322035 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.165421  [   10/  522]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.322020 \n",
      "\n",
      "Task 4\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.164654  [   10/ 1630]\n",
      "loss: 2.163928  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.570972 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.161106  [   10/ 1630]\n",
      "loss: 2.162145  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.570907 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.163572  [   10/ 1630]\n",
      "loss: 2.164357  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.570819 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.160835  [   10/ 1630]\n",
      "loss: 2.154101  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.570222 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.154273  [   10/ 1630]\n",
      "loss: 1.187674  [ 1010/ 1630]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.508206 \n",
      "\n",
      "Task 5\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.955737  [   10/ 1928]\n",
      "loss: 1.236516  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.606281 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.190040  [   10/ 1928]\n",
      "loss: 1.273422  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.623141 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.168507  [   10/ 1928]\n",
      "loss: 1.168737  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 1.626410 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.172681  [   10/ 1928]\n",
      "loss: 1.166759  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.627724 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.236825  [   10/ 1928]\n",
      "loss: 1.170189  [ 1010/ 1928]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.628125 \n",
      "\n",
      "Task 6\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.105368  [   10/ 2636]\n",
      "loss: 2.050176  [ 1010/ 2636]\n",
      "loss: 1.814025  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.581925 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.490117  [   10/ 2636]\n",
      "loss: 1.282908  [ 1010/ 2636]\n",
      "loss: 1.201879  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.8%, Avg loss: 1.853275 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.192948  [   10/ 2636]\n",
      "loss: 1.187344  [ 1010/ 2636]\n",
      "loss: 1.183368  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.887329 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.186135  [   10/ 2636]\n",
      "loss: 1.172725  [ 1010/ 2636]\n",
      "loss: 1.172441  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.895598 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.172663  [   10/ 2636]\n",
      "loss: 1.173614  [ 1010/ 2636]\n",
      "loss: 1.168674  [ 2010/ 2636]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.898831 \n",
      "\n",
      "Task 7\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.165407  [   10/ 3546]\n",
      "loss: 2.165038  [ 1010/ 3546]\n",
      "loss: 2.165250  [ 2010/ 3546]\n",
      "loss: 2.165350  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.968324 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165366  [   10/ 3546]\n",
      "loss: 2.165125  [ 1010/ 3546]\n",
      "loss: 2.165105  [ 2010/ 3546]\n",
      "loss: 2.165322  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.968241 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165301  [   10/ 3546]\n",
      "loss: 2.164597  [ 1010/ 3546]\n",
      "loss: 2.165359  [ 2010/ 3546]\n",
      "loss: 2.165192  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.968152 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.165389  [   10/ 3546]\n",
      "loss: 2.165353  [ 1010/ 3546]\n",
      "loss: 2.165312  [ 2010/ 3546]\n",
      "loss: 2.165298  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.967399 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.165152  [   10/ 3546]\n",
      "loss: 2.165005  [ 1010/ 3546]\n",
      "loss: 2.165020  [ 2010/ 3546]\n",
      "loss: 2.165182  [ 3010/ 3546]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 1.967948 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for task_id in range(train_dataloader.get_tasks_length()):\n",
    "    print(f\"Task {task_id+1}\\n-------------------------------\")\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(model, train_dataloader.get_task(task_id), loss_fn, optimizer)\n",
    "        test(model, train_dataloader.get_task_range(0, task_id+1), loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
